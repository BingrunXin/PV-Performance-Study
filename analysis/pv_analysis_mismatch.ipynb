{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-23T04:26:06.841560Z",
     "start_time": "2025-08-23T04:25:55.391022Z"
    }
   },
   "source": [
    "# ----------------- EDIT ONLY THE PATHS BELOW -----------------\n",
    "PHASE1_PATH = r\"D:\\SolarTiltProject\\data\\data_150ohm.csv\"        # <-- path to Phase I 150Ω CSV (GBK)\n",
    "BLOCKS_SUM = r\"D:\\SolarTiltProject\\data\\20-200ohm\\blocks_summary.csv\" # <-- path to blocks_summary.csv (GBK)\n",
    "RAW_SWEEP = r\"D:\\SolarTiltProject\\data\\data_20-200ohm.csv\"  # <-- optional raw sweep CSV (GBK) or \"\" if none\n",
    "OUT_DIR = r\"D:\\SolarTiltProject\\data\\mismatch\"                      # <-- output dir for CSV + plots\n",
    "ENCODING = \"gbk\"   # <- file encoding, e.g., \"gbk\" or \"utf-8\"\n",
    "RESAMPLE_FREQ = None   # <- e.g. '1T' to resample Phase I to 1-minute cadence (or None)\n",
    "VERBOSE = True\n",
    "# ==============================================\n",
    "\n",
    "import warnings, math\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "out_dir = Path(OUT_DIR)\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def vlog(*a, **kw):\n",
    "    if VERBOSE:\n",
    "        print(*a, **kw)\n",
    "\n",
    "# ----- helper: encoding-safe read -----\n",
    "def read_csv_try_enc(path, enc_first=ENCODING, **kwargs):\n",
    "    p = Path(path)\n",
    "    if not p.exists():\n",
    "        raise FileNotFoundError(f\"File not found: {p}\")\n",
    "    tried = []\n",
    "    enc_list = [enc_first, 'utf-8', 'utf-8-sig', 'cp1252', 'latin-1']\n",
    "    for e in enc_list:\n",
    "        try:\n",
    "            df = pd.read_csv(p, encoding=e, engine='python', dtype=str, **kwargs)\n",
    "            vlog(f\"Read {p.name} with encoding='{e}'\")\n",
    "            return df\n",
    "        except Exception as exc:\n",
    "            tried.append((e,str(exc)))\n",
    "    # final fallback\n",
    "    df = pd.read_csv(p, engine='python', dtype=str, **kwargs)\n",
    "    vlog(f\"Read {p.name} with pandas default engine (fallback)\")\n",
    "    return df\n",
    "\n",
    "# ----- column detection helpers -----\n",
    "def find_datetime_col(df):\n",
    "    for c in df.columns:\n",
    "        lc = c.lower()\n",
    "        if 'time' in lc or 'date' in lc or 'timestamp' in lc:\n",
    "            return c\n",
    "    # fallback: first parseable\n",
    "    for c in df.columns:\n",
    "        try:\n",
    "            parsed = pd.to_datetime(df[c].dropna().astype(str).iloc[:8], errors='coerce')\n",
    "            if parsed.notna().any():\n",
    "                return c\n",
    "        except Exception:\n",
    "            pass\n",
    "    return None\n",
    "\n",
    "def find_power_col(df):\n",
    "    prefs = ['pmax','p_max','pmax_w','pmax_w','p_max_w','mean_power_w','mean_power','power_w','power']\n",
    "    for p in prefs:\n",
    "        for c in df.columns:\n",
    "            if c.lower().replace(' ','_') == p:\n",
    "                return c\n",
    "    # heuristic: any column name containing 'power' or 'pmax'\n",
    "    for c in df.columns:\n",
    "        if 'power' in c.lower() or 'pmax' in c.lower():\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "def find_voltage_current_cols(df):\n",
    "    v = None; i = None\n",
    "    for c in df.columns:\n",
    "        lc = c.lower()\n",
    "        if 'volt' in lc or lc == 'v':\n",
    "            if v is None: v = c\n",
    "        if 'current' in lc or 'amp' in lc or lc == 'i':\n",
    "            if i is None: i = c\n",
    "    return v, i\n",
    "\n",
    "# ----- Phase II: determine MPP and Ropt (prefer blocks_summary, else raw sweep) -----\n",
    "bs_df = read_csv_try_enc(BLOCKS_SUM, skip_blank_lines=False)\n",
    "vlog(\"blocks_summary columns:\", bs_df.columns.tolist())\n",
    "\n",
    "# try to obtain Pmax and Ropt from blocks_summary (if you already marked them)\n",
    "Pmax_from_bs = None\n",
    "Vmp_from_bs = None\n",
    "Imp_from_bs = None\n",
    "Ropt_from_bs = None\n",
    "\n",
    "# common candidate names\n",
    "candidate_names = {\n",
    "    'pmax': ['pmax','p_max','pmax_w','p_max_w','pmax_watt','pmax_watts','Pmax','P_max','Pmax_W'],\n",
    "    'vmp': ['vmp','v_mp','vmp_v','Vmp','V_mp','Vmp_V'],\n",
    "    'imp': ['imp','i_mp','imp_a','Imp','I_mp','Imp_A'],\n",
    "    'ropt':['r_opt','r_at_mpp','r_opt_ohm','Ropt','R_opt','R_at_mpp','R']\n",
    "}\n",
    "\n",
    "# lower-cased keys for matching\n",
    "cols_lc = {c.lower():c for c in bs_df.columns}\n",
    "\n",
    "# helper to find any of a list in columns (case-insensitive)\n",
    "def find_col_by_list(dfcols, names_list):\n",
    "    for nm in names_list:\n",
    "        for c in dfcols:\n",
    "            if c.lower().replace(' ','_') == nm.lower().replace(' ','_'):\n",
    "                return c\n",
    "    # fallback fuzzy contains\n",
    "    for nm in names_list:\n",
    "        for c in dfcols:\n",
    "            if nm.lower().replace('_','') in c.lower().replace('_',''):\n",
    "                return c\n",
    "    return None\n",
    "\n",
    "# If blocks_summary has multiple rows, use the row that is marked or the max-power row\n",
    "# We'll try to find the first row with numeric Pmax candidate; otherwise choose idxmax if numeric col exists\n",
    "# 1) search for Pmax-like column name\n",
    "pcol = find_power_col(bs_df)\n",
    "if pcol is not None:\n",
    "    # coerce numeric\n",
    "    try:\n",
    "        bs_df[pcol] = pd.to_numeric(bs_df[pcol], errors='coerce')\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "# pick the representative block row:\n",
    "rep_row = None\n",
    "if bs_df.shape[0] == 1:\n",
    "    rep_row = bs_df.iloc[0]\n",
    "else:\n",
    "    # if one column explicitly named 'Sweep_ID' or 'block' etc you might have chosen; otherwise pick the row with largest numeric power if present\n",
    "    if pcol is not None and bs_df[pcol].notna().any():\n",
    "        rep_idx = bs_df[pcol].astype(float).idxmax()\n",
    "        rep_row = bs_df.loc[rep_idx]\n",
    "    else:\n",
    "        # default to first non-empty row\n",
    "        rep_row = bs_df.iloc[0]\n",
    "\n",
    "# attempt to extract values from the representative row\n",
    "if rep_row is not None:\n",
    "    # Pmax\n",
    "    col_p = find_col_by_list(bs_df.columns, candidate_names['pmax'])\n",
    "    if col_p is not None and str(rep_row.get(col_p)).strip() != '':\n",
    "        try:\n",
    "            Pmax_from_bs = float(str(rep_row[col_p]).strip())\n",
    "        except Exception:\n",
    "            Pmax_from_bs = None\n",
    "    # Vmp\n",
    "    col_v = find_col_by_list(bs_df.columns, candidate_names['vmp'])\n",
    "    if col_v is not None and str(rep_row.get(col_v)).strip() != '':\n",
    "        try:\n",
    "            Vmp_from_bs = float(str(rep_row[col_v]).strip())\n",
    "        except Exception:\n",
    "            Vmp_from_bs = None\n",
    "    # Imp\n",
    "    col_i = find_col_by_list(bs_df.columns, candidate_names['imp'])\n",
    "    if col_i is not None and str(rep_row.get(col_i)).strip() != '':\n",
    "        try:\n",
    "            Imp_from_bs = float(str(rep_row[col_i]).strip())\n",
    "        except Exception:\n",
    "            Imp_from_bs = None\n",
    "    # Ropt\n",
    "    col_r = find_col_by_list(bs_df.columns, candidate_names['ropt'])\n",
    "    if col_r is not None and str(rep_row.get(col_r)).strip() != '':\n",
    "        try:\n",
    "            Ropt_from_bs = float(str(rep_row[col_r]).strip())\n",
    "        except Exception:\n",
    "            Ropt_from_bs = None\n",
    "\n",
    "vlog(\"From blocks_summary (if present): Pmax=\", Pmax_from_bs, \"Vmp=\", Vmp_from_bs, \"Imp=\", Imp_from_bs, \"Ropt=\", Ropt_from_bs)\n",
    "\n",
    "# If necessary, compute MPP from RAW_SWEEP\n",
    "Pmax_computed = None; Vmp_computed = None; Imp_computed = None; Ropt_computed = None\n",
    "sweep_used = None\n",
    "\n",
    "raw_path = Path(RAW_SWEEP)\n",
    "if raw_path.exists():\n",
    "    raw_df = read_csv_try_enc(RAW_SWEEP)\n",
    "    tcol = find_datetime_col(raw_df)\n",
    "    vcol, icol = find_voltage_current_cols(raw_df)\n",
    "    pcol = find_power_col(raw_df)\n",
    "    # coerce numeric where possible\n",
    "    for c in raw_df.columns:\n",
    "        try:\n",
    "            raw_df[c] = pd.to_numeric(raw_df[c], errors='coerce')\n",
    "        except Exception:\n",
    "            pass\n",
    "    # compute power if needed\n",
    "    if pcol is None:\n",
    "        if vcol is not None and icol is not None:\n",
    "            # ensure current in A (if values >> 10 assume mA)\n",
    "            if raw_df[icol].median(skipna=True) is not np.nan and raw_df[icol].median(skipna=True) > 10:\n",
    "                raw_df[icol] = raw_df[icol] / 1000.0\n",
    "            raw_df['Power_calc'] = raw_df[vcol] * raw_df[icol]\n",
    "            pcol = 'Power_calc'\n",
    "        elif vcol is not None:\n",
    "            # maybe sweep with resistor recorded -> try V^2/R if R column exists\n",
    "            rcol = next((c for c in raw_df.columns if 'resist' in c.lower() or 'ohm' in c.lower() or 'res'==c.lower()), None)\n",
    "            if rcol is not None:\n",
    "                raw_df['Power_calc'] = raw_df[vcol]**2 / pd.to_numeric(raw_df[rcol], errors='coerce').replace({0:np.nan})\n",
    "                pcol = 'Power_calc'\n",
    "    # find max-power row\n",
    "    if pcol is not None and raw_df[pcol].notna().any():\n",
    "        idx_max = raw_df[pcol].astype(float).idxmax()\n",
    "        Pmax_computed = float(raw_df.loc[idx_max, pcol])\n",
    "        if vcol is not None:\n",
    "            Vmp_computed = float(raw_df.loc[idx_max, vcol])\n",
    "        if icol is not None:\n",
    "            Imp_computed = float(raw_df.loc[idx_max, icol])\n",
    "        # if current was mA and we converted earlier, Imp_computed is in A\n",
    "        if Vmp_computed is not None and Imp_computed is not None and Imp_computed != 0:\n",
    "            Ropt_computed = Vmp_computed / Imp_computed\n",
    "        # determine sweep timestamp if available\n",
    "        if tcol is not None and pd.notna(raw_df.loc[idx_max, tcol]):\n",
    "            sweep_used = pd.to_datetime(raw_df.loc[idx_max, tcol], errors='coerce')\n",
    "    vlog(\"Computed from raw sweep: Pmax=\", Pmax_computed, \"Vmp=\", Vmp_computed, \"Imp=\", Imp_computed, \"Ropt=\", Ropt_computed)\n",
    "\n",
    "# FINAL: choose authoritative values (priority: blocks_summary values if present, else computed)\n",
    "Pmax = Pmax_from_bs if Pmax_from_bs is not None else Pmax_computed\n",
    "Vmp  = Vmp_from_bs  if Vmp_from_bs  is not None else Vmp_computed\n",
    "Imp  = Imp_from_bs  if Imp_from_bs  is not None else Imp_computed\n",
    "Ropt = Ropt_from_bs if Ropt_from_bs is not None else Ropt_computed\n",
    "\n",
    "# If still missing Pmax, fail with clear message\n",
    "if Pmax is None:\n",
    "    raise RuntimeError(\"Pmax not found in blocks_summary and could not be computed from RAW_SWEEP. Please ensure one of them contains power values.\")\n",
    "\n",
    "vlog(\"Final authoritative MPP values being used:\")\n",
    "vlog(f\"  Pmax = {Pmax:.5g} W\")\n",
    "if (Vmp is not None) and (Imp is not None):\n",
    "    vlog(f\"  Vmp = {Vmp:.5g} V, Imp = {Imp:.5g} A, Ropt = {Ropt:.5g} Ω\")\n",
    "else:\n",
    "    vlog(\"  Note: Vmp/Imp not fully available; Ropt may be NaN\")\n",
    "\n",
    "# If both blocks_summary Pmax and computed Pmax exist and differ, warn and report both\n",
    "if (Pmax_from_bs is not None) and (Pmax_computed is not None):\n",
    "    rel_diff = abs(Pmax_from_bs - Pmax_computed) / max(abs(Pmax_computed),1e-12)\n",
    "    if rel_diff > 0.01:\n",
    "        vlog(\"WARNING: Pmax in blocks_summary differs from Pmax computed from RAW_SWEEP by {:.2%}\".format(rel_diff))\n",
    "        vlog(\"  blocks_summary Pmax =\", Pmax_from_bs, \"; computed Pmax =\", Pmax_computed)\n",
    "\n",
    "# ----- Now compute mismatch against Phase I 150Ω timeseries -----\n",
    "# load Phase I and preprocess duplicates\n",
    "phase1_df = read_csv_try_enc(PHASE1_PATH)\n",
    "dtcol = find_datetime_col(phase1_df)\n",
    "if dtcol is None:\n",
    "    raise RuntimeError(\"Phase I file has no detectable datetime column.\")\n",
    "# parse and aggregate duplicates\n",
    "phase1_df[dtcol] = pd.to_datetime(phase1_df[dtcol].astype(str), errors='coerce')\n",
    "phase1_df = phase1_df.dropna(subset=[dtcol]).set_index(dtcol).sort_index()\n",
    "# coerce numerics\n",
    "for c in phase1_df.columns:\n",
    "    try: phase1_df[c] = pd.to_numeric(phase1_df[c], errors='coerce')\n",
    "    except: pass\n",
    "# aggregate duplicate timestamps by mean\n",
    "if not phase1_df.index.is_unique:\n",
    "    phase1_df = phase1_df.groupby(phase1_df.index).mean()\n",
    "# determine power column\n",
    "pcol150 = find_power_col(phase1_df)\n",
    "if pcol150 is None:\n",
    "    vcol150, icol150 = find_voltage_current_cols(phase1_df)\n",
    "    if (vcol150 is not None) and (icol150 is not None):\n",
    "        # convert current to A if needed heuristically\n",
    "        if phase1_df[icol150].median(skipna=True) is not np.nan and phase1_df[icol150].median(skipna=True) > 10:\n",
    "            phase1_df[icol150] = phase1_df[icol150] / 1000.0\n",
    "        phase1_df['Power_W'] = phase1_df[vcol150] * phase1_df[icol150]\n",
    "        pcol150 = 'Power_W'\n",
    "    elif vcol150 is not None:\n",
    "        phase1_df['Power_W'] = (phase1_df[vcol150]**2) / 150.0\n",
    "        pcol150 = 'Power_W'\n",
    "    else:\n",
    "        raise RuntimeError(\"Phase I file: cannot determine or compute Power column.\")\n",
    "\n",
    "phase1_df[pcol150] = pd.to_numeric(phase1_df[pcol150], errors='coerce')\n",
    "\n",
    "# find nearest phase1 sample to sweep timestamp\n",
    "# prefer sweep_used (from raw sweep), else try to use timestamp in blocks_summary row\n",
    "sweep_ts = None\n",
    "# try blocks_summary timestamp field\n",
    "for cand in ['time_of_mpp','time','start_time','end_time','timestamp','datetime','date','day']:\n",
    "    if cand in bs_df.columns and pd.notna(rep_row.get(cand)):\n",
    "        try:\n",
    "            sweep_ts = pd.to_datetime(str(rep_row.get(cand)), errors='coerce')\n",
    "            if not pd.isna(sweep_ts):\n",
    "                break\n",
    "        except Exception:\n",
    "            sweep_ts = None\n",
    "# if not found, use sweep_used from computed raw sweep\n",
    "if (sweep_ts is None or pd.isna(sweep_ts)) and (sweep_used is not None):\n",
    "    sweep_ts = sweep_used\n",
    "# final fallback: use timestamp of phase1 peak\n",
    "if sweep_ts is None or pd.isna(sweep_ts):\n",
    "    sweep_ts = phase1_df[pcol150].astype(float).idxmax()\n",
    "vlog(\"Using sweep timestamp:\", sweep_ts)\n",
    "\n",
    "# robust nearest-sample lookup (works even if coarse timestamps)\n",
    "time_diffs = (phase1_df.index.to_series() - pd.to_datetime(sweep_ts)).abs()\n",
    "if time_diffs.empty:\n",
    "    raise RuntimeError(\"Phase I has no valid timestamps after preprocessing.\")\n",
    "nearest_pos = int(np.argmin(time_diffs.values))\n",
    "nearest_time = phase1_df.index[nearest_pos]\n",
    "P150_at_sweep = float(phase1_df.iloc[nearest_pos][pcol150])\n",
    "vlog(f\"Nearest Phase I sample time: {nearest_time} -> Power @150Ω = {P150_at_sweep:.5g} W\")\n",
    "\n",
    "# instantaneous mismatch\n",
    "instant_mismatch_pct = 100.0 * (Pmax - P150_at_sweep) / Pmax\n",
    "\n",
    "# conservative daily energy loss\n",
    "day = nearest_time.normalize()\n",
    "mask = (phase1_df.index >= day) & (phase1_df.index < day + pd.Timedelta(days=1))\n",
    "df_day = phase1_df.loc[mask]\n",
    "if df_day.empty:\n",
    "    E150_Wh = np.nan; Emax_Wh = np.nan; daily_loss_pct = np.nan\n",
    "else:\n",
    "    times = (df_day.index.view('int64')/1e9).astype(float)\n",
    "    Pvals = df_day[pcol150].astype(float).values\n",
    "    E150_J = np.trapz(Pvals, times) if len(Pvals) >= 2 else 0.0\n",
    "    E150_Wh = E150_J / 3600.0\n",
    "    Pmax_arr = np.full_like(Pvals, fill_value=Pmax, dtype=float)\n",
    "    Emax_J = np.trapz(Pmax_arr, times) if len(Pmax_arr) >= 2 else Pmax * ( (times[-1]-times[0]) if len(times)>=2 else 0.0 )\n",
    "    Emax_Wh = Emax_J / 3600.0\n",
    "    daily_loss_pct = 100.0 * (Emax_Wh - E150_Wh) / Emax_Wh if Emax_Wh > 0 else np.nan\n",
    "\n",
    "# Save summary and overlay plot\n",
    "out_dict = {\n",
    "    'sweep_timestamp_used': [str(sweep_ts)],\n",
    "    'Pmax_sweep_W': [Pmax],\n",
    "    'Vmp_used_V': [Vmp],\n",
    "    'Imp_used_A': [Imp],\n",
    "    'Ropt_used_Ohm': [Ropt],\n",
    "    'P150_nearest_W': [P150_at_sweep],\n",
    "    'instantaneous_mismatch_pct': [instant_mismatch_pct],\n",
    "    'day': [str(day.date())],\n",
    "    'E_150_Wh': [E150_Wh],\n",
    "    'E_max_Wh': [Emax_Wh],\n",
    "    'daily_loss_pct': [daily_loss_pct]\n",
    "}\n",
    "out_df = pd.DataFrame(out_dict)\n",
    "csv_out = out_dir / \"mismatch_summary.csv\"\n",
    "out_df.to_csv(csv_out, index=False, encoding='utf-8')\n",
    "vlog(\"Saved mismatch_summary.csv ->\", csv_out)\n",
    "\n",
    "# overlay plot: Phase I power for that day + horizontal Pmax\n",
    "if not df_day.empty:\n",
    "    fig, ax = plt.subplots(figsize=(10,4))\n",
    "    ax.plot(df_day.index, df_day[pcol150], marker='o', linewidth=1, label='Power At 150Ω (mW)')\n",
    "    ax.axhline(Pmax, color='C1', linestyle='--', label=f'Pmax (sweep) = {Pmax:.3f} mW')\n",
    "    ax.fill_between(df_day.index, df_day[pcol150], Pmax, where=(Pmax>df_day[pcol150]), color='C1', alpha=0.25)\n",
    "    ax.set_xlabel('Time')\n",
    "    ax.set_ylabel('Power (mW)')\n",
    "    ax.set_title('Phase I power (150Ω) on sweep day — overlay with sweep Pmax')\n",
    "    ax.legend()\n",
    "    plt.tight_layout()\n",
    "    img_out = out_dir / \"mismatch_overlay.png\"\n",
    "    fig.savefig(img_out, dpi=300, bbox_inches='tight')\n",
    "    vlog(\"Saved overlay image ->\", img_out)\n",
    "    plt.show()\n",
    "else:\n",
    "    vlog(\"No Phase I daytime data for the sweep day -> overlay not generated.\")\n",
    "\n",
    "# Final printed summary for your report — definitive values\n",
    "print(\"\\n===== Final Mismatch Summary (authoritative) =====\")\n",
    "print(f\"Pmax used (W) ............: {Pmax:.5g}\")\n",
    "print(f\"Vmp used (V) .............: {Vmp if Vmp is not None else 'N/A'}\")\n",
    "print(f\"Imp used (A) .............: {Imp if Imp is not None else 'N/A'}\")\n",
    "print(f\"Ropt used (Ohm) ..........: {Ropt if Ropt is not None else 'N/A'}\")\n",
    "print(f\"P150 at nearest sample (W): {P150_at_sweep:.5g}  (time {nearest_time})\")\n",
    "print(f\"Instantaneous mismatch (%) : {instant_mismatch_pct:.3f} %\")\n",
    "print(f\"Conservative daily loss (%) : {daily_loss_pct if not pd.isna(daily_loss_pct) else 'N/A'}\")\n",
    "print(\"Saved CSV:\", csv_out)\n",
    "if not df_day.empty:\n",
    "    print(\"Saved overlay image:\", img_out)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read blocks_summary.csv with encoding='gbk'\n",
      "blocks_summary columns: ['Block_ID', 'Resistance_Ohm', 'n_rows', 'mean_voltage_V', 'mean_current_A', 'mean_power_W', 'std_power_W', 'mean_light_lux', 'mean_panel_temp_C']\n",
      "From blocks_summary (if present): Pmax= None Vmp= None Imp= None Ropt= 25.0\n",
      "Read data_20-200ohm.csv with encoding='gbk'\n",
      "Computed from raw sweep: Pmax= 7772.5 Vmp= 17.029 Imp= nan Ropt= nan\n",
      "Final authoritative MPP values being used:\n",
      "  Pmax = 7772.5 W\n",
      "  Vmp = 17.029 V, Imp = nan A, Ropt = 25 Ω\n",
      "Read data_150ohm.csv with encoding='gbk'\n",
      "Using sweep timestamp: 2025-08-17 11:10:00\n",
      "Nearest Phase I sample time: 2025-08-17 11:10:00 -> Power @150Ω = 2632.5 W\n",
      "Saved mismatch_summary.csv -> D:\\SolarTiltProject\\data\\mismatch\\mismatch_summary.csv\n",
      "Saved overlay image -> D:\\SolarTiltProject\\data\\mismatch\\mismatch_overlay.png\n",
      "\n",
      "===== Final Mismatch Summary (authoritative) =====\n",
      "Pmax used (W) ............: 7772.5\n",
      "Vmp used (V) .............: 17.029\n",
      "Imp used (A) .............: nan\n",
      "Ropt used (Ohm) ..........: 25.0\n",
      "P150 at nearest sample (W): 2632.5  (time 2025-08-17 11:10:00)\n",
      "Instantaneous mismatch (%) : 66.131 %\n",
      "Conservative daily loss (%) : 78.58740673818579\n",
      "Saved CSV: D:\\SolarTiltProject\\data\\mismatch\\mismatch_summary.csv\n",
      "Saved overlay image: D:\\SolarTiltProject\\data\\mismatch\\mismatch_overlay.png\n"
     ]
    }
   ],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
